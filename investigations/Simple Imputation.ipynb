{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Imputation\n",
    "\n",
    "Investigation of principled imputation for very simple cases i.e. under the assumption that the observations are Gaussian and that the data is MAR/ MCAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from scipy import stats\n",
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,y = load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a mask for the missingness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = np.random.rand(*X.shape) > 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "masked_X = X.copy()\n",
    "masked_X[mask] = np.NaN\n",
    "pd.DataFrame(masked_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean = np.nanmean(masked_X, axis=0)\n",
    "std = np.nanstd(masked_X, axis=0)\n",
    "scaled_X = (masked_X - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(scaled_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most simple approach possible (without loosing data) - Mean Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_imputed_X = scaled_X.copy()\n",
    "mean_imputed_X[np.isnan(mean_imputed_X)] = np.nanmean(scaled_X, axis=0)[np.where(np.isnan(mean_imputed_X))[1]]\n",
    "mean_imputed_X = (mean_imputed_X)*std + mean\n",
    "\n",
    "pd.DataFrame(mean_imputed_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean(np.power(mean_imputed_X-X,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets try using a multivariate gaussian with ML esimtation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def g_ll(imputed_X, μ, Σ):\n",
    "    ll = 0\n",
    "    for i in range(imputed_X.shape[0]):\n",
    "        ll += stats.multivariate_normal.pdf(imputed_X[i,:], mean=μ, cov=Σ)\n",
    "    return np.log(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "μML = np.nanmean(masked_X, axis = 0)\n",
    "μML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_max = masked_X.shape[0]\n",
    "ΣML = np.zeros((X.shape[1], X.shape[1]))\n",
    "# to keep track of how often the xi combinations have been seen together\n",
    "counts = np.zeros((X.shape[1], X.shape[1]))\n",
    "ΣML = np.zeros((X.shape[1], X.shape[1]))\n",
    "\n",
    "for i in range(masked_X.shape[0]):\n",
    "    X_row = masked_X[i,:]\n",
    "    # figure out which values are missing\n",
    "    valid_locs = np.where(~np.isnan(X_row))[0]\n",
    "    coords = tuple(zip(*[(i, j) for i in valid_locs for j in valid_locs]))\n",
    "    \n",
    "    # update the counts\n",
    "    counts[coords] += 1\n",
    "    \n",
    "    # get the x vals and the means\n",
    "    μ = μML[valid_locs]\n",
    "    x = X_row[valid_locs]\n",
    "    \n",
    "    # calc the variance\n",
    "    diff = x - μ\n",
    "    Σ = np.outer(diff, diff.T)\n",
    "    \n",
    "    # update variance \n",
    "    size = len(valid_locs)\n",
    "    rescale = np.multiply((counts[coords] - 1), ΣML[coords]).reshape(size, size)\n",
    "    add = (Σ + rescale)\n",
    "    ΣML[coords] = (add/(counts[coords].reshape(size, size))).reshape(size*size) # do we need the -1? makes performance worse also seems to make the cov matrix not pos def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the covariance matrix is +ve def\n",
    "np.all(linalg.eigvals(ΣML) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# impute by taking the mean of the conditional distro\n",
    "def impute(input_X, μ, Λ):\n",
    "    imputed_X = input_X.copy()\n",
    "    for i in range(imputed_X.shape[0]):\n",
    "        X_row = imputed_X[i,:]\n",
    "        # if there are no missing values then go to next iter\n",
    "        if np.all(~np.isnan(X_row)): continue\n",
    "\n",
    "        # figure out which values are missing\n",
    "        b_locs = np.where(~np.isnan(X_row))[0]\n",
    "        a_locs = np.where(np.isnan(X_row))[0]\n",
    "        ab_coords = tuple(zip(*[(i, j) for i in a_locs for j in b_locs]))\n",
    "        aa_coords = tuple(zip(*[(i, j) for i in a_locs for j in a_locs]))\n",
    "\n",
    "        # get the subsets of the precision matrices\n",
    "        Λaa = Λ[aa_coords].reshape(len(a_locs), len(a_locs))\n",
    "        Λab = Λ[ab_coords].reshape(len(a_locs), len(b_locs))\n",
    "\n",
    "        # calculate the mean of a|b\n",
    "        μab = μ[a_locs] - linalg.inv(Λaa) @ Λab @ (X_row[b_locs] - μ[b_locs])\n",
    "        imputed_X[i,:][a_locs] = μab\n",
    "        \n",
    "    return imputed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calc the inverse of the covariance matrix - the precision matrix\n",
    "ΛML = np.linalg.inv(ΣML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ML_imputed_X = impute(masked_X, μML, ΛML)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(ML_imputed_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean(np.power(ML_imputed_X-X,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_ll(ML_imputed_X, μML, ΣML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(ML_imputed_X - X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EM estimation of ML\n",
    "\n",
    "The above ML estimation is a bit of a hack - lets see how it compares to the EM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # start with random μ and Σ\n",
    "μEM = np.random.rand(*μML.shape)\n",
    "ΣEM = np.random.rand(*ΣML.shape)\n",
    "# μEM = np.nanmean(scaled_X, axis=0)\n",
    "# ΣEM = np.eye(scaled_X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    if i == 0:\n",
    "        # using the current parameters, estiamte the values of the missing data:\n",
    "        ΛEM = np.linalg.inv(ΣEM)\n",
    "        # impute by taking the mean of the conditional distro\n",
    "        EM_imputed_X = impute(scaled_X, μEM, ΛEM)\n",
    "\n",
    "    # now re-estimate μEM and ΣEM\n",
    "    μEM = np.mean(EM_imputed_X, axis = 0)\n",
    "    diff = EM_imputed_X - μEM\n",
    "    ΣEM = (diff.T @ diff)/diff.shape[0]\n",
    "    \n",
    "    # using the current parameters, estiamte the values of the missing data:\n",
    "    ΛEM = linalg.inv(ΣEM)\n",
    "    # impute by taking the mean of the conditional distro\n",
    "    EM_imputed_X = impute(scaled_X, μEM, ΛEM)\n",
    "    \n",
    "    # calc RMSE and LL\n",
    "    print(np.sqrt(np.mean(np.power(EM_imputed_X*std + mean - X,2))))\n",
    "    print(g_ll(EM_imputed_X, μEM, ΛEM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the covariance matrix is +ve def\n",
    "np.all(np.linalg.eigvals(ΣEM) > 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
